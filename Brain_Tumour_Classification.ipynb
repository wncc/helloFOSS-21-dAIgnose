{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Brain_Tumour_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWXSxFrQHMg_"
      },
      "source": [
        "<h1> Brain Tumour Classification\n",
        "\n",
        "In this Notebook you will design your own model for the identification and classification of brain tumour.\n",
        "\n",
        "The dataset can be found over <a href = \"https://drive.google.com/file/d/1IhdM-fzj-Egyy8-frVDs04LVW7Y3r4on/view?usp=sharing\">here.</a>\n",
        "\n",
        "Download the Dataset and unzip it in a Folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbzWUxypHMUA"
      },
      "source": [
        "### We will first import the libraries required to load and preprocess the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RwWPuclj7xK"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YAlzdRZHAqJ"
      },
      "source": [
        "\n",
        "\n",
        "<p> There are two ways to preprocess the dataset \n",
        "<ul>\n",
        "    <li> Using the <a href = \"https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow_from_directory\">flow_from_directory</a> function of the <a href = \"https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\">ImageDataGenerator</a> class where the data is automatically divided into classes. We can include image augmentation and preprocessing in this itself which will lead to less memory usage as the augmented images are loaded directly and not stored anywhere</li>\n",
        "    <li> Using the <a href = \"https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\">ImageDataGenerator</a> to create a data generator and dividing your data into classes on your own. In this case the generator created by you will be used in the training directly</li>\n",
        "</ul>\n",
        "<br>\n",
        "<p> Try both the approaches once. In the first approach you will need to to create a generator first and then use the <a href = \"https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow_from_directory\">flow_from_directory</a> function on the datagen with the path of the training or validation dataset as one of the arguments.  \n",
        "\n",
        "Feel free to choose any other methods also (<a href = \"https://www.tensorflow.org/api_docs/python/tf/data/Dataset\">Dataset</a> API)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bL_shCaALquW"
      },
      "source": [
        "# method 1 as an example\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=60.,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range= 0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode = \"reflect\" #Data augmentation\n",
        ")\n",
        "\n",
        "val_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train = train_gen.flow_from_directory(\n",
        "    'content/train', #training path\n",
        "    target_size=(256, 256),\n",
        "    batch_size=32,\n",
        "    class_mode = 'categorical'\n",
        ")\n",
        "\n",
        "val = val_gen.flow_from_directory(\n",
        "    'content/val', #validation path\n",
        "    target_size=(256, 256),\n",
        "    batch_size=32,\n",
        "    class_mode = 'categorical'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5ColvXPLdVW"
      },
      "source": [
        "# Try executing method 2 on your own"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUCyUb5WMIE0"
      },
      "source": [
        "<p>Next step is designing the architecture of the model\n",
        "\n",
        "Do checkout the <a href = \"https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\">Sequential</a> API, <a href = \"https://www.tensorflow.org/api_docs/python/tf/keras/Model\">Model</a> API and the <a href = \"https://www.tensorflow.org/guide/keras/functional\">Functional</a> API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSEcG5vOLg8Z"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(64,(3,3),activation='relu')) \n",
        "model.add(tf.keras.layers.BatchNormalization()) \n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(64,(3,3),activation='relu')) \n",
        "model.add(tf.keras.layers.BatchNormalization()) \n",
        "model.add(tf.keras.layers.Dropout(0.2)) \n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(64,(3,3),activation='relu')) \n",
        "model.add(tf.keras.layers.BatchNormalization()) \n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(64,(3,3),activation='relu')) \n",
        "model.add(tf.keras.layers.BatchNormalization()) \n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(64,(3,3),activation='relu')) \n",
        "model.add(tf.keras.layers.BatchNormalization()) \n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(4,activation='relu')) \n",
        "\n",
        "\n",
        "#add different layers in the model using model.add(...)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-s0bU2rpNcs_"
      },
      "source": [
        "<p> Choose suitable Loss Functions, optimizers and metrics "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbfMer52NWTG"
      },
      "source": [
        "model.compile(optimizer = None, loss = None, metrics = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59ntbytYN51Y"
      },
      "source": [
        "<p> Print the model summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzgfOJGKNo9F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwSo6CjvN8-0"
      },
      "source": [
        "<p>Train the model using the fit method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lX5Rx6dlOCZ6"
      },
      "source": [
        "history = model.fit(\n",
        "    #train data,\n",
        "    epochs=None, \n",
        "    validation_data = None,\n",
        "    verbose = None,\n",
        "    callbacks = None\n",
        "    steps_per_epoch = None\n",
        ")\n",
        "\n",
        "# remember if u are using the method 2 to load the dataset u will need to load the training data using the flow function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h59XvQySO2d_"
      },
      "source": [
        "<p> Plot all the graphs of the losses and accuracies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31E5YEL_O2Ia"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc,  label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}